# statistics
Statistics Samples for ML/AI
**What is the mean, and how is it used in machine learning?**
The mean is the average of a set of values, calculated as the sum of all values divided by the number of values. In machine learning, the mean is often used as a baseline to compare model performance and to center data (mean normalization) to improve model convergence.

**What is variance, and why is it important in machine learning?**
Variance measures the dispersion of a set of values around the mean, calculated as the average of the squared differences from the mean. In machine learning, variance indicates how much the model's predictions are spread out, which helps in understanding model stability and overfitting. High variance suggests that the model is overfitting the training data.

**What is the standard deviation, and how does it differ from variance?**
The standard deviation is the square root of the variance and represents the average distance of each data point from the mean. While variance gives the spread of the data in squared units, the standard deviation provides a measure in the same units as the data, making it more interpretable.

